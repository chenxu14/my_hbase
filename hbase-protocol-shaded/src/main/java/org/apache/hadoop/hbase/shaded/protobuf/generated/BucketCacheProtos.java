// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: BucketCacheEntry.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

public final class BucketCacheProtos {
  private BucketCacheProtos() {}
  public static void registerAllExtensions(
      org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.BlockPriority}
   */
  public enum BlockPriority
      implements org.apache.hadoop.hbase.shaded.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>single = 0;</code>
     */
    single(0),
    /**
     * <code>multi = 1;</code>
     */
    multi(1),
    /**
     * <code>memory = 2;</code>
     */
    memory(2),
    ;

    /**
     * <code>single = 0;</code>
     */
    public static final int single_VALUE = 0;
    /**
     * <code>multi = 1;</code>
     */
    public static final int multi_VALUE = 1;
    /**
     * <code>memory = 2;</code>
     */
    public static final int memory_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static BlockPriority valueOf(int value) {
      return forNumber(value);
    }

    public static BlockPriority forNumber(int value) {
      switch (value) {
        case 0: return single;
        case 1: return multi;
        case 2: return memory;
        default: return null;
      }
    }

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<BlockPriority>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<
        BlockPriority> internalValueMap =
          new org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<BlockPriority>() {
            public BlockPriority findValueByNumber(int number) {
              return BlockPriority.forNumber(number);
            }
          };

    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final BlockPriority[] VALUES = values();

    public static BlockPriority valueOf(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private BlockPriority(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.BlockPriority)
  }

  public interface BucketCacheEntryOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BucketCacheEntry)
      org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int64 cache_capacity = 1;</code>
     */
    boolean hasCacheCapacity();
    /**
     * <code>required int64 cache_capacity = 1;</code>
     */
    long getCacheCapacity();

    /**
     * <code>required string io_class = 2;</code>
     */
    boolean hasIoClass();
    /**
     * <code>required string io_class = 2;</code>
     */
    java.lang.String getIoClass();
    /**
     * <code>required string io_class = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getIoClassBytes();

    /**
     * <code>required string map_class = 3;</code>
     */
    boolean hasMapClass();
    /**
     * <code>required string map_class = 3;</code>
     */
    java.lang.String getMapClass();
    /**
     * <code>required string map_class = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getMapClassBytes();

    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */
    int getDeserializersCount();
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */
    boolean containsDeserializers(
        int key);
    /**
     * Use {@link #getDeserializersMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.Integer, java.lang.String>
    getDeserializers();
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */
    java.util.Map<java.lang.Integer, java.lang.String>
    getDeserializersMap();
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    java.lang.String getDeserializersOrDefault(
        int key,
        java.lang.String defaultValue);
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    java.lang.String getDeserializersOrThrow(
        int key);

    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    boolean hasBackingMap();
    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getBackingMap();
    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder getBackingMapOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.BucketCacheEntry}
   */
  public  static final class BucketCacheEntry extends
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BucketCacheEntry)
      BucketCacheEntryOrBuilder {
    // Use BucketCacheEntry.newBuilder() to construct.
    private BucketCacheEntry(org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BucketCacheEntry() {
      cacheCapacity_ = 0L;
      ioClass_ = "";
      mapClass_ = "";
    }

    @java.lang.Override
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BucketCacheEntry(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              cacheCapacity_ = input.readInt64();
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              ioClass_ = bs;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              mapClass_ = bs;
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                deserializers_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField.newMapField(
                    DeserializersDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000008;
              }
              org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry<java.lang.Integer, java.lang.String>
              deserializers__ = input.readMessage(
                  DeserializersDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              deserializers_.getMutableMap().put(
                  deserializers__.getKey(), deserializers__.getValue());
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = backingMap_.toBuilder();
              }
              backingMap_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(backingMap_);
                backingMap_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 4:
          return internalGetDeserializers();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.Builder.class);
    }

    private int bitField0_;
    public static final int CACHE_CAPACITY_FIELD_NUMBER = 1;
    private long cacheCapacity_;
    /**
     * <code>required int64 cache_capacity = 1;</code>
     */
    public boolean hasCacheCapacity() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required int64 cache_capacity = 1;</code>
     */
    public long getCacheCapacity() {
      return cacheCapacity_;
    }

    public static final int IO_CLASS_FIELD_NUMBER = 2;
    private volatile java.lang.Object ioClass_;
    /**
     * <code>required string io_class = 2;</code>
     */
    public boolean hasIoClass() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required string io_class = 2;</code>
     */
    public java.lang.String getIoClass() {
      java.lang.Object ref = ioClass_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = 
            (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          ioClass_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string io_class = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getIoClassBytes() {
      java.lang.Object ref = ioClass_;
      if (ref instanceof java.lang.String) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
            org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        ioClass_ = b;
        return b;
      } else {
        return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int MAP_CLASS_FIELD_NUMBER = 3;
    private volatile java.lang.Object mapClass_;
    /**
     * <code>required string map_class = 3;</code>
     */
    public boolean hasMapClass() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required string map_class = 3;</code>
     */
    public java.lang.String getMapClass() {
      java.lang.Object ref = mapClass_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = 
            (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          mapClass_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string map_class = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getMapClassBytes() {
      java.lang.Object ref = mapClass_;
      if (ref instanceof java.lang.String) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
            org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mapClass_ = b;
        return b;
      } else {
        return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DESERIALIZERS_FIELD_NUMBER = 4;
    private static final class DeserializersDefaultEntryHolder {
      static final org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry<
          java.lang.Integer, java.lang.String> defaultEntry =
              org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry
              .<java.lang.Integer, java.lang.String>newDefaultInstance(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_descriptor, 
                  org.apache.hadoop.hbase.shaded.com.google.protobuf.WireFormat.FieldType.INT32,
                  0,
                  org.apache.hadoop.hbase.shaded.com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField<
        java.lang.Integer, java.lang.String> deserializers_;
    private org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField<java.lang.Integer, java.lang.String>
    internalGetDeserializers() {
      if (deserializers_ == null) {
        return org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField.emptyMapField(
            DeserializersDefaultEntryHolder.defaultEntry);
      }
      return deserializers_;
    }

    public int getDeserializersCount() {
      return internalGetDeserializers().getMap().size();
    }
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    public boolean containsDeserializers(
        int key) {
      
      return internalGetDeserializers().getMap().containsKey(key);
    }
    /**
     * Use {@link #getDeserializersMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.Integer, java.lang.String> getDeserializers() {
      return getDeserializersMap();
    }
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    public java.util.Map<java.lang.Integer, java.lang.String> getDeserializersMap() {
      return internalGetDeserializers().getMap();
    }
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    public java.lang.String getDeserializersOrDefault(
        int key,
        java.lang.String defaultValue) {
      
      java.util.Map<java.lang.Integer, java.lang.String> map =
          internalGetDeserializers().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <code>map&lt;int32, string&gt; deserializers = 4;</code>
     */

    public java.lang.String getDeserializersOrThrow(
        int key) {
      
      java.util.Map<java.lang.Integer, java.lang.String> map =
          internalGetDeserializers().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int BACKING_MAP_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap backingMap_;
    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    public boolean hasBackingMap() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getBackingMap() {
      return backingMap_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance() : backingMap_;
    }
    /**
     * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder getBackingMapOrBuilder() {
      return backingMap_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance() : backingMap_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCacheCapacity()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasIoClass()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMapClass()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasBackingMap()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getBackingMap().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, cacheCapacity_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, ioClass_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, mapClass_);
      }
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
        .serializeIntegerMapTo(
          output,
          internalGetDeserializers(),
          DeserializersDefaultEntryHolder.defaultEntry,
          4);
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(5, getBackingMap());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, cacheCapacity_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, ioClass_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, mapClass_);
      }
      for (java.util.Map.Entry<java.lang.Integer, java.lang.String> entry
           : internalGetDeserializers().getMap().entrySet()) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.MapEntry<java.lang.Integer, java.lang.String>
        deserializers__ = DeserializersDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
            .computeMessageSize(4, deserializers__);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getBackingMap());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry other = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry) obj;

      boolean result = true;
      result = result && (hasCacheCapacity() == other.hasCacheCapacity());
      if (hasCacheCapacity()) {
        result = result && (getCacheCapacity()
            == other.getCacheCapacity());
      }
      result = result && (hasIoClass() == other.hasIoClass());
      if (hasIoClass()) {
        result = result && getIoClass()
            .equals(other.getIoClass());
      }
      result = result && (hasMapClass() == other.hasMapClass());
      if (hasMapClass()) {
        result = result && getMapClass()
            .equals(other.getMapClass());
      }
      result = result && internalGetDeserializers().equals(
          other.internalGetDeserializers());
      result = result && (hasBackingMap() == other.hasBackingMap());
      if (hasBackingMap()) {
        result = result && getBackingMap()
            .equals(other.getBackingMap());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasCacheCapacity()) {
        hash = (37 * hash) + CACHE_CAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.hashLong(
            getCacheCapacity());
      }
      if (hasIoClass()) {
        hash = (37 * hash) + IO_CLASS_FIELD_NUMBER;
        hash = (53 * hash) + getIoClass().hashCode();
      }
      if (hasMapClass()) {
        hash = (37 * hash) + MAP_CLASS_FIELD_NUMBER;
        hash = (53 * hash) + getMapClass().hashCode();
      }
      if (!internalGetDeserializers().getMap().isEmpty()) {
        hash = (37 * hash) + DESERIALIZERS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetDeserializers().hashCode();
      }
      if (hasBackingMap()) {
        hash = (37 * hash) + BACKING_MAP_FIELD_NUMBER;
        hash = (53 * hash) + getBackingMap().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(byte[] data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        byte[] data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BucketCacheEntry}
     */
    public static final class Builder extends
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BucketCacheEntry)
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntryOrBuilder {
      public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 4:
            return internalGetDeserializers();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 4:
            return internalGetMutableDeserializers();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getBackingMapFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        cacheCapacity_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        ioClass_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        mapClass_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        internalGetMutableDeserializers().clear();
        if (backingMapBuilder_ == null) {
          backingMap_ = null;
        } else {
          backingMapBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketCacheEntry_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry result = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.cacheCapacity_ = cacheCapacity_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.ioClass_ = ioClass_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.mapClass_ = mapClass_;
        result.deserializers_ = internalGetDeserializers();
        result.deserializers_.makeImmutable();
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000008;
        }
        if (backingMapBuilder_ == null) {
          result.backingMap_ = backingMap_;
        } else {
          result.backingMap_ = backingMapBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry.getDefaultInstance()) return this;
        if (other.hasCacheCapacity()) {
          setCacheCapacity(other.getCacheCapacity());
        }
        if (other.hasIoClass()) {
          bitField0_ |= 0x00000002;
          ioClass_ = other.ioClass_;
          onChanged();
        }
        if (other.hasMapClass()) {
          bitField0_ |= 0x00000004;
          mapClass_ = other.mapClass_;
          onChanged();
        }
        internalGetMutableDeserializers().mergeFrom(
            other.internalGetDeserializers());
        if (other.hasBackingMap()) {
          mergeBackingMap(other.getBackingMap());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasCacheCapacity()) {
          return false;
        }
        if (!hasIoClass()) {
          return false;
        }
        if (!hasMapClass()) {
          return false;
        }
        if (!hasBackingMap()) {
          return false;
        }
        if (!getBackingMap().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long cacheCapacity_ ;
      /**
       * <code>required int64 cache_capacity = 1;</code>
       */
      public boolean hasCacheCapacity() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required int64 cache_capacity = 1;</code>
       */
      public long getCacheCapacity() {
        return cacheCapacity_;
      }
      /**
       * <code>required int64 cache_capacity = 1;</code>
       */
      public Builder setCacheCapacity(long value) {
        bitField0_ |= 0x00000001;
        cacheCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 cache_capacity = 1;</code>
       */
      public Builder clearCacheCapacity() {
        bitField0_ = (bitField0_ & ~0x00000001);
        cacheCapacity_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object ioClass_ = "";
      /**
       * <code>required string io_class = 2;</code>
       */
      public boolean hasIoClass() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string io_class = 2;</code>
       */
      public java.lang.String getIoClass() {
        java.lang.Object ref = ioClass_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs =
              (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            ioClass_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string io_class = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
          getIoClassBytes() {
        java.lang.Object ref = ioClass_;
        if (ref instanceof String) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          ioClass_ = b;
          return b;
        } else {
          return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string io_class = 2;</code>
       */
      public Builder setIoClass(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        ioClass_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string io_class = 2;</code>
       */
      public Builder clearIoClass() {
        bitField0_ = (bitField0_ & ~0x00000002);
        ioClass_ = getDefaultInstance().getIoClass();
        onChanged();
        return this;
      }
      /**
       * <code>required string io_class = 2;</code>
       */
      public Builder setIoClassBytes(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        ioClass_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object mapClass_ = "";
      /**
       * <code>required string map_class = 3;</code>
       */
      public boolean hasMapClass() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required string map_class = 3;</code>
       */
      public java.lang.String getMapClass() {
        java.lang.Object ref = mapClass_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs =
              (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            mapClass_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string map_class = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
          getMapClassBytes() {
        java.lang.Object ref = mapClass_;
        if (ref instanceof String) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          mapClass_ = b;
          return b;
        } else {
          return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string map_class = 3;</code>
       */
      public Builder setMapClass(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        mapClass_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string map_class = 3;</code>
       */
      public Builder clearMapClass() {
        bitField0_ = (bitField0_ & ~0x00000004);
        mapClass_ = getDefaultInstance().getMapClass();
        onChanged();
        return this;
      }
      /**
       * <code>required string map_class = 3;</code>
       */
      public Builder setMapClassBytes(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        mapClass_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField<
          java.lang.Integer, java.lang.String> deserializers_;
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField<java.lang.Integer, java.lang.String>
      internalGetDeserializers() {
        if (deserializers_ == null) {
          return org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField.emptyMapField(
              DeserializersDefaultEntryHolder.defaultEntry);
        }
        return deserializers_;
      }
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField<java.lang.Integer, java.lang.String>
      internalGetMutableDeserializers() {
        onChanged();;
        if (deserializers_ == null) {
          deserializers_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.MapField.newMapField(
              DeserializersDefaultEntryHolder.defaultEntry);
        }
        if (!deserializers_.isMutable()) {
          deserializers_ = deserializers_.copy();
        }
        return deserializers_;
      }

      public int getDeserializersCount() {
        return internalGetDeserializers().getMap().size();
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public boolean containsDeserializers(
          int key) {
        
        return internalGetDeserializers().getMap().containsKey(key);
      }
      /**
       * Use {@link #getDeserializersMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Integer, java.lang.String> getDeserializers() {
        return getDeserializersMap();
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public java.util.Map<java.lang.Integer, java.lang.String> getDeserializersMap() {
        return internalGetDeserializers().getMap();
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public java.lang.String getDeserializersOrDefault(
          int key,
          java.lang.String defaultValue) {
        
        java.util.Map<java.lang.Integer, java.lang.String> map =
            internalGetDeserializers().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public java.lang.String getDeserializersOrThrow(
          int key) {
        
        java.util.Map<java.lang.Integer, java.lang.String> map =
            internalGetDeserializers().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearDeserializers() {
        getMutableDeserializers().clear();
        return this;
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public Builder removeDeserializers(
          int key) {
        
        getMutableDeserializers().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Integer, java.lang.String>
      getMutableDeserializers() {
        return internalGetMutableDeserializers().getMutableMap();
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */
      public Builder putDeserializers(
          int key,
          java.lang.String value) {
        
        if (value == null) { throw new java.lang.NullPointerException(); }
        getMutableDeserializers().put(key, value);
        return this;
      }
      /**
       * <code>map&lt;int32, string&gt; deserializers = 4;</code>
       */

      public Builder putAllDeserializers(
          java.util.Map<java.lang.Integer, java.lang.String> values) {
        getMutableDeserializers().putAll(values);
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap backingMap_ = null;
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder> backingMapBuilder_;
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public boolean hasBackingMap() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getBackingMap() {
        if (backingMapBuilder_ == null) {
          return backingMap_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance() : backingMap_;
        } else {
          return backingMapBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public Builder setBackingMap(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap value) {
        if (backingMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          backingMap_ = value;
          onChanged();
        } else {
          backingMapBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public Builder setBackingMap(
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder builderForValue) {
        if (backingMapBuilder_ == null) {
          backingMap_ = builderForValue.build();
          onChanged();
        } else {
          backingMapBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public Builder mergeBackingMap(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap value) {
        if (backingMapBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              backingMap_ != null &&
              backingMap_ != org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance()) {
            backingMap_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.newBuilder(backingMap_).mergeFrom(value).buildPartial();
          } else {
            backingMap_ = value;
          }
          onChanged();
        } else {
          backingMapBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public Builder clearBackingMap() {
        if (backingMapBuilder_ == null) {
          backingMap_ = null;
          onChanged();
        } else {
          backingMapBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder getBackingMapBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getBackingMapFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder getBackingMapOrBuilder() {
        if (backingMapBuilder_ != null) {
          return backingMapBuilder_.getMessageOrBuilder();
        } else {
          return backingMap_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance() : backingMap_;
        }
      }
      /**
       * <code>required .hbase.pb.BackingMap backing_map = 5;</code>
       */
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder> 
          getBackingMapFieldBuilder() {
        if (backingMapBuilder_ == null) {
          backingMapBuilder_ = new org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder>(
                  getBackingMap(),
                  getParentForChildren(),
                  isClean());
          backingMap_ = null;
        }
        return backingMapBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BucketCacheEntry)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BucketCacheEntry)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketCacheEntry>
        PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BucketCacheEntry>() {
      public BucketCacheEntry parsePartialFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
          return new BucketCacheEntry(input, extensionRegistry);
      }
    };

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketCacheEntry> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketCacheEntry> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketCacheEntry getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BackingMapOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BackingMap)
      org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> 
        getEntryList();
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getEntry(int index);
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    int getEntryCount();
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder> 
        getEntryOrBuilderList();
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder getEntryOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.BackingMap}
   */
  public  static final class BackingMap extends
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BackingMap)
      BackingMapOrBuilder {
    // Use BackingMap.newBuilder() to construct.
    private BackingMap(org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BackingMap() {
      entry_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BackingMap(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                entry_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry>();
                mutable_bitField0_ |= 0x00000001;
              }
              entry_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          entry_ = java.util.Collections.unmodifiableList(entry_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMap_descriptor;
    }

    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMap_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder.class);
    }

    public static final int ENTRY_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> entry_;
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> getEntryList() {
      return entry_;
    }
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder> 
        getEntryOrBuilderList() {
      return entry_;
    }
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    public int getEntryCount() {
      return entry_.size();
    }
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getEntry(int index) {
      return entry_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder getEntryOrBuilder(
        int index) {
      return entry_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getEntryCount(); i++) {
        if (!getEntry(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < entry_.size(); i++) {
        output.writeMessage(1, entry_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < entry_.size(); i++) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, entry_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap other = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap) obj;

      boolean result = true;
      result = result && getEntryList()
          .equals(other.getEntryList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getEntryCount() > 0) {
        hash = (37 * hash) + ENTRY_FIELD_NUMBER;
        hash = (53 * hash) + getEntryList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(byte[] data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        byte[] data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BackingMap}
     */
    public static final class Builder extends
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BackingMap)
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapOrBuilder {
      public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMap_descriptor;
      }

      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMap_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getEntryFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          entryBuilder_.clear();
        }
        return this;
      }

      public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMap_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap result = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap(this);
        int from_bitField0_ = bitField0_;
        if (entryBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            entry_ = java.util.Collections.unmodifiableList(entry_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.entry_ = entry_;
        } else {
          result.entry_ = entryBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap.getDefaultInstance()) return this;
        if (entryBuilder_ == null) {
          if (!other.entry_.isEmpty()) {
            if (entry_.isEmpty()) {
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureEntryIsMutable();
              entry_.addAll(other.entry_);
            }
            onChanged();
          }
        } else {
          if (!other.entry_.isEmpty()) {
            if (entryBuilder_.isEmpty()) {
              entryBuilder_.dispose();
              entryBuilder_ = null;
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
              entryBuilder_ = 
                org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getEntryFieldBuilder() : null;
            } else {
              entryBuilder_.addAllMessages(other.entry_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getEntryCount(); i++) {
          if (!getEntry(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> entry_ =
        java.util.Collections.emptyList();
      private void ensureEntryIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          entry_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry>(entry_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hadoop.hbase.shaded.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder> entryBuilder_;

      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> getEntryList() {
        if (entryBuilder_ == null) {
          return java.util.Collections.unmodifiableList(entry_);
        } else {
          return entryBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public int getEntryCount() {
        if (entryBuilder_ == null) {
          return entry_.size();
        } else {
          return entryBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getEntry(int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);
        } else {
          return entryBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder setEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.set(index, value);
          onChanged();
        } else {
          entryBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder setEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.set(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder addEntry(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(value);
          onChanged();
        } else {
          entryBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder addEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(index, value);
          onChanged();
        } else {
          entryBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder addEntry(
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder addEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder addAllEntry(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry> values) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, entry_);
          onChanged();
        } else {
          entryBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder clearEntry() {
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          entryBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public Builder removeEntry(int index) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.remove(index);
          onChanged();
        } else {
          entryBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder getEntryBuilder(
          int index) {
        return getEntryFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder getEntryOrBuilder(
          int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);  } else {
          return entryBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder> 
           getEntryOrBuilderList() {
        if (entryBuilder_ != null) {
          return entryBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(entry_);
        }
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder addEntryBuilder() {
        return getEntryFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder addEntryBuilder(
          int index) {
        return getEntryFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BackingMapEntry entry = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder> 
           getEntryBuilderList() {
        return getEntryFieldBuilder().getBuilderList();
      }
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder> 
          getEntryFieldBuilder() {
        if (entryBuilder_ == null) {
          entryBuilder_ = new org.apache.hadoop.hbase.shaded.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder>(
                  entry_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          entry_ = null;
        }
        return entryBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BackingMap)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BackingMap)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMap>
        PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BackingMap>() {
      public BackingMap parsePartialFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
          return new BackingMap(input, extensionRegistry);
      }
    };

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMap> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMap> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMap getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BackingMapEntryOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BackingMapEntry)
      org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getKey();
    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder getKeyOrBuilder();

    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getValue();
    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.BackingMapEntry}
   */
  public  static final class BackingMapEntry extends
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BackingMapEntry)
      BackingMapEntryOrBuilder {
    // Use BackingMapEntry.newBuilder() to construct.
    private BackingMapEntry(org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BackingMapEntry() {
    }

    @java.lang.Override
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BackingMapEntry(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = key_.toBuilder();
              }
              key_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(key_);
                key_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMapEntry_descriptor;
    }

    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMapEntry_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey key_;
    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getKey() {
      return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance() : key_;
    }
    /**
     * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder getKeyOrBuilder() {
      return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance() : key_;
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry value_;
    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getValue() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance() : value_;
    }
    /**
     * <code>required .hbase.pb.BucketEntry value = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder getValueOrBuilder() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance() : value_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasKey()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getKey().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getValue().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getKey());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getValue());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getKey());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getValue());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry other = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(byte[] data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        byte[] data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BackingMapEntry}
     */
    public static final class Builder extends
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BackingMapEntry)
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntryOrBuilder {
      public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMapEntry_descriptor;
      }

      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMapEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getKeyFieldBuilder();
          getValueFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (keyBuilder_ == null) {
          key_ = null;
        } else {
          keyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = null;
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BackingMapEntry_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry result = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (keyBuilder_ == null) {
          result.key_ = key_;
        } else {
          result.key_ = keyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry.getDefaultInstance()) return this;
        if (other.hasKey()) {
          mergeKey(other.getKey());
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasKey()) {
          return false;
        }
        if (!hasValue()) {
          return false;
        }
        if (!getKey().isInitialized()) {
          return false;
        }
        if (!getValue().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey key_ = null;
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder> keyBuilder_;
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getKey() {
        if (keyBuilder_ == null) {
          return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance() : key_;
        } else {
          return keyBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public Builder setKey(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey value) {
        if (keyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          key_ = value;
          onChanged();
        } else {
          keyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public Builder setKey(
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder builderForValue) {
        if (keyBuilder_ == null) {
          key_ = builderForValue.build();
          onChanged();
        } else {
          keyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public Builder mergeKey(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey value) {
        if (keyBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              key_ != null &&
              key_ != org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance()) {
            key_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.newBuilder(key_).mergeFrom(value).buildPartial();
          } else {
            key_ = value;
          }
          onChanged();
        } else {
          keyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public Builder clearKey() {
        if (keyBuilder_ == null) {
          key_ = null;
          onChanged();
        } else {
          keyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder getKeyBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder getKeyOrBuilder() {
        if (keyBuilder_ != null) {
          return keyBuilder_.getMessageOrBuilder();
        } else {
          return key_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance() : key_;
        }
      }
      /**
       * <code>required .hbase.pb.BlockCacheKey key = 1;</code>
       */
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder> 
          getKeyFieldBuilder() {
        if (keyBuilder_ == null) {
          keyBuilder_ = new org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder>(
                  getKey(),
                  getParentForChildren(),
                  isClean());
          key_ = null;
        }
        return keyBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry value_ = null;
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder> valueBuilder_;
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getValue() {
        if (valueBuilder_ == null) {
          return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance() : value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != null &&
              value_ != org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = null;
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance() : value_;
        }
      }
      /**
       * <code>required .hbase.pb.BucketEntry value = 2;</code>
       */
      private org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new org.apache.hadoop.hbase.shaded.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder>(
                  getValue(),
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BackingMapEntry)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BackingMapEntry)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMapEntry>
        PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BackingMapEntry>() {
      public BackingMapEntry parsePartialFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
          return new BackingMapEntry(input, extensionRegistry);
      }
    };

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMapEntry> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BackingMapEntry> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BackingMapEntry getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BlockCacheKeyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BlockCacheKey)
      org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string hfilename = 1;</code>
     */
    boolean hasHfilename();
    /**
     * <code>required string hfilename = 1;</code>
     */
    java.lang.String getHfilename();
    /**
     * <code>required string hfilename = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getHfilenameBytes();

    /**
     * <code>required int64 offset = 2;</code>
     */
    boolean hasOffset();
    /**
     * <code>required int64 offset = 2;</code>
     */
    long getOffset();

    /**
     * <code>required bool primary_replica_block = 3;</code>
     */
    boolean hasPrimaryReplicaBlock();
    /**
     * <code>required bool primary_replica_block = 3;</code>
     */
    boolean getPrimaryReplicaBlock();
  }
  /**
   * Protobuf type {@code hbase.pb.BlockCacheKey}
   */
  public  static final class BlockCacheKey extends
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BlockCacheKey)
      BlockCacheKeyOrBuilder {
    // Use BlockCacheKey.newBuilder() to construct.
    private BlockCacheKey(org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BlockCacheKey() {
      hfilename_ = "";
      offset_ = 0L;
      primaryReplicaBlock_ = false;
    }

    @java.lang.Override
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BlockCacheKey(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              hfilename_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              offset_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              primaryReplicaBlock_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BlockCacheKey_descriptor;
    }

    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BlockCacheKey_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder.class);
    }

    private int bitField0_;
    public static final int HFILENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object hfilename_;
    /**
     * <code>required string hfilename = 1;</code>
     */
    public boolean hasHfilename() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string hfilename = 1;</code>
     */
    public java.lang.String getHfilename() {
      java.lang.Object ref = hfilename_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs = 
            (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          hfilename_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string hfilename = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
        getHfilenameBytes() {
      java.lang.Object ref = hfilename_;
      if (ref instanceof java.lang.String) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
            org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        hfilename_ = b;
        return b;
      } else {
        return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int OFFSET_FIELD_NUMBER = 2;
    private long offset_;
    /**
     * <code>required int64 offset = 2;</code>
     */
    public boolean hasOffset() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required int64 offset = 2;</code>
     */
    public long getOffset() {
      return offset_;
    }

    public static final int PRIMARY_REPLICA_BLOCK_FIELD_NUMBER = 3;
    private boolean primaryReplicaBlock_;
    /**
     * <code>required bool primary_replica_block = 3;</code>
     */
    public boolean hasPrimaryReplicaBlock() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool primary_replica_block = 3;</code>
     */
    public boolean getPrimaryReplicaBlock() {
      return primaryReplicaBlock_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasHfilename()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasOffset()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPrimaryReplicaBlock()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, hfilename_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, offset_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, primaryReplicaBlock_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, hfilename_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, offset_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, primaryReplicaBlock_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey other = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey) obj;

      boolean result = true;
      result = result && (hasHfilename() == other.hasHfilename());
      if (hasHfilename()) {
        result = result && getHfilename()
            .equals(other.getHfilename());
      }
      result = result && (hasOffset() == other.hasOffset());
      if (hasOffset()) {
        result = result && (getOffset()
            == other.getOffset());
      }
      result = result && (hasPrimaryReplicaBlock() == other.hasPrimaryReplicaBlock());
      if (hasPrimaryReplicaBlock()) {
        result = result && (getPrimaryReplicaBlock()
            == other.getPrimaryReplicaBlock());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHfilename()) {
        hash = (37 * hash) + HFILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getHfilename().hashCode();
      }
      if (hasOffset()) {
        hash = (37 * hash) + OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.hashLong(
            getOffset());
      }
      if (hasPrimaryReplicaBlock()) {
        hash = (37 * hash) + PRIMARY_REPLICA_BLOCK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.hashBoolean(
            getPrimaryReplicaBlock());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(byte[] data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        byte[] data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BlockCacheKey}
     */
    public static final class Builder extends
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BlockCacheKey)
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKeyOrBuilder {
      public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BlockCacheKey_descriptor;
      }

      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BlockCacheKey_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        hfilename_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        offset_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        primaryReplicaBlock_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BlockCacheKey_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey result = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.hfilename_ = hfilename_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.offset_ = offset_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.primaryReplicaBlock_ = primaryReplicaBlock_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey.getDefaultInstance()) return this;
        if (other.hasHfilename()) {
          bitField0_ |= 0x00000001;
          hfilename_ = other.hfilename_;
          onChanged();
        }
        if (other.hasOffset()) {
          setOffset(other.getOffset());
        }
        if (other.hasPrimaryReplicaBlock()) {
          setPrimaryReplicaBlock(other.getPrimaryReplicaBlock());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasHfilename()) {
          return false;
        }
        if (!hasOffset()) {
          return false;
        }
        if (!hasPrimaryReplicaBlock()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object hfilename_ = "";
      /**
       * <code>required string hfilename = 1;</code>
       */
      public boolean hasHfilename() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string hfilename = 1;</code>
       */
      public java.lang.String getHfilename() {
        java.lang.Object ref = hfilename_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString bs =
              (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            hfilename_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string hfilename = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString
          getHfilenameBytes() {
        java.lang.Object ref = hfilename_;
        if (ref instanceof String) {
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString b = 
              org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          hfilename_ = b;
          return b;
        } else {
          return (org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string hfilename = 1;</code>
       */
      public Builder setHfilename(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        hfilename_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string hfilename = 1;</code>
       */
      public Builder clearHfilename() {
        bitField0_ = (bitField0_ & ~0x00000001);
        hfilename_ = getDefaultInstance().getHfilename();
        onChanged();
        return this;
      }
      /**
       * <code>required string hfilename = 1;</code>
       */
      public Builder setHfilenameBytes(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        hfilename_ = value;
        onChanged();
        return this;
      }

      private long offset_ ;
      /**
       * <code>required int64 offset = 2;</code>
       */
      public boolean hasOffset() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required int64 offset = 2;</code>
       */
      public long getOffset() {
        return offset_;
      }
      /**
       * <code>required int64 offset = 2;</code>
       */
      public Builder setOffset(long value) {
        bitField0_ |= 0x00000002;
        offset_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 offset = 2;</code>
       */
      public Builder clearOffset() {
        bitField0_ = (bitField0_ & ~0x00000002);
        offset_ = 0L;
        onChanged();
        return this;
      }

      private boolean primaryReplicaBlock_ ;
      /**
       * <code>required bool primary_replica_block = 3;</code>
       */
      public boolean hasPrimaryReplicaBlock() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool primary_replica_block = 3;</code>
       */
      public boolean getPrimaryReplicaBlock() {
        return primaryReplicaBlock_;
      }
      /**
       * <code>required bool primary_replica_block = 3;</code>
       */
      public Builder setPrimaryReplicaBlock(boolean value) {
        bitField0_ |= 0x00000004;
        primaryReplicaBlock_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool primary_replica_block = 3;</code>
       */
      public Builder clearPrimaryReplicaBlock() {
        bitField0_ = (bitField0_ & ~0x00000004);
        primaryReplicaBlock_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BlockCacheKey)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BlockCacheKey)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BlockCacheKey>
        PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BlockCacheKey>() {
      public BlockCacheKey parsePartialFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
          return new BlockCacheKey(input, extensionRegistry);
      }
    };

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BlockCacheKey> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BlockCacheKey> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockCacheKey getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BucketEntryOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BucketEntry)
      org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int64 offset = 1;</code>
     */
    boolean hasOffset();
    /**
     * <code>required int64 offset = 1;</code>
     */
    long getOffset();

    /**
     * <code>required int32 length = 2;</code>
     */
    boolean hasLength();
    /**
     * <code>required int32 length = 2;</code>
     */
    int getLength();

    /**
     * <code>required int64 access_counter = 3;</code>
     */
    boolean hasAccessCounter();
    /**
     * <code>required int64 access_counter = 3;</code>
     */
    long getAccessCounter();

    /**
     * <code>required int32 deserialiser_index = 4;</code>
     */
    boolean hasDeserialiserIndex();
    /**
     * <code>required int32 deserialiser_index = 4;</code>
     */
    int getDeserialiserIndex();

    /**
     * <code>required .hbase.pb.BlockPriority priority = 5;</code>
     */
    boolean hasPriority();
    /**
     * <code>required .hbase.pb.BlockPriority priority = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority getPriority();
  }
  /**
   * Protobuf type {@code hbase.pb.BucketEntry}
   */
  public  static final class BucketEntry extends
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BucketEntry)
      BucketEntryOrBuilder {
    // Use BucketEntry.newBuilder() to construct.
    private BucketEntry(org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BucketEntry() {
      offset_ = 0L;
      length_ = 0;
      accessCounter_ = 0L;
      deserialiserIndex_ = 0;
      priority_ = 0;
    }

    @java.lang.Override
    public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private BucketEntry(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              offset_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              length_ = input.readInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              accessCounter_ = input.readInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              deserialiserIndex_ = input.readInt32();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority value = org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                priority_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketEntry_descriptor;
    }

    protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketEntry_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder.class);
    }

    private int bitField0_;
    public static final int OFFSET_FIELD_NUMBER = 1;
    private long offset_;
    /**
     * <code>required int64 offset = 1;</code>
     */
    public boolean hasOffset() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required int64 offset = 1;</code>
     */
    public long getOffset() {
      return offset_;
    }

    public static final int LENGTH_FIELD_NUMBER = 2;
    private int length_;
    /**
     * <code>required int32 length = 2;</code>
     */
    public boolean hasLength() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required int32 length = 2;</code>
     */
    public int getLength() {
      return length_;
    }

    public static final int ACCESS_COUNTER_FIELD_NUMBER = 3;
    private long accessCounter_;
    /**
     * <code>required int64 access_counter = 3;</code>
     */
    public boolean hasAccessCounter() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required int64 access_counter = 3;</code>
     */
    public long getAccessCounter() {
      return accessCounter_;
    }

    public static final int DESERIALISER_INDEX_FIELD_NUMBER = 4;
    private int deserialiserIndex_;
    /**
     * <code>required int32 deserialiser_index = 4;</code>
     */
    public boolean hasDeserialiserIndex() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required int32 deserialiser_index = 4;</code>
     */
    public int getDeserialiserIndex() {
      return deserialiserIndex_;
    }

    public static final int PRIORITY_FIELD_NUMBER = 5;
    private int priority_;
    /**
     * <code>required .hbase.pb.BlockPriority priority = 5;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>required .hbase.pb.BlockPriority priority = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority getPriority() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority result = org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority.valueOf(priority_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority.single : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasOffset()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasLength()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasAccessCounter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDeserialiserIndex()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPriority()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, offset_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, length_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, accessCounter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, deserialiserIndex_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, priority_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, offset_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, length_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, accessCounter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, deserialiserIndex_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, priority_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry other = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry) obj;

      boolean result = true;
      result = result && (hasOffset() == other.hasOffset());
      if (hasOffset()) {
        result = result && (getOffset()
            == other.getOffset());
      }
      result = result && (hasLength() == other.hasLength());
      if (hasLength()) {
        result = result && (getLength()
            == other.getLength());
      }
      result = result && (hasAccessCounter() == other.hasAccessCounter());
      if (hasAccessCounter()) {
        result = result && (getAccessCounter()
            == other.getAccessCounter());
      }
      result = result && (hasDeserialiserIndex() == other.hasDeserialiserIndex());
      if (hasDeserialiserIndex()) {
        result = result && (getDeserialiserIndex()
            == other.getDeserialiserIndex());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && priority_ == other.priority_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasOffset()) {
        hash = (37 * hash) + OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.hashLong(
            getOffset());
      }
      if (hasLength()) {
        hash = (37 * hash) + LENGTH_FIELD_NUMBER;
        hash = (53 * hash) + getLength();
      }
      if (hasAccessCounter()) {
        hash = (37 * hash) + ACCESS_COUNTER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.hashLong(
            getAccessCounter());
      }
      if (hasDeserialiserIndex()) {
        hash = (37 * hash) + DESERIALISER_INDEX_FIELD_NUMBER;
        hash = (53 * hash) + getDeserialiserIndex();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + priority_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(byte[] data)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        byte[] data,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parseFrom(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
        org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BucketEntry}
     */
    public static final class Builder extends
        org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BucketEntry)
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntryOrBuilder {
      public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketEntry_descriptor;
      }

      protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        offset_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        length_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        accessCounter_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        deserialiserIndex_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        priority_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.internal_static_hbase_pb_BucketEntry_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry result = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.offset_ = offset_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.length_ = length_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.accessCounter_ = accessCounter_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.deserialiserIndex_ = deserialiserIndex_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.priority_ = priority_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry.getDefaultInstance()) return this;
        if (other.hasOffset()) {
          setOffset(other.getOffset());
        }
        if (other.hasLength()) {
          setLength(other.getLength());
        }
        if (other.hasAccessCounter()) {
          setAccessCounter(other.getAccessCounter());
        }
        if (other.hasDeserialiserIndex()) {
          setDeserialiserIndex(other.getDeserialiserIndex());
        }
        if (other.hasPriority()) {
          setPriority(other.getPriority());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasOffset()) {
          return false;
        }
        if (!hasLength()) {
          return false;
        }
        if (!hasAccessCounter()) {
          return false;
        }
        if (!hasDeserialiserIndex()) {
          return false;
        }
        if (!hasPriority()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long offset_ ;
      /**
       * <code>required int64 offset = 1;</code>
       */
      public boolean hasOffset() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required int64 offset = 1;</code>
       */
      public long getOffset() {
        return offset_;
      }
      /**
       * <code>required int64 offset = 1;</code>
       */
      public Builder setOffset(long value) {
        bitField0_ |= 0x00000001;
        offset_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 offset = 1;</code>
       */
      public Builder clearOffset() {
        bitField0_ = (bitField0_ & ~0x00000001);
        offset_ = 0L;
        onChanged();
        return this;
      }

      private int length_ ;
      /**
       * <code>required int32 length = 2;</code>
       */
      public boolean hasLength() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required int32 length = 2;</code>
       */
      public int getLength() {
        return length_;
      }
      /**
       * <code>required int32 length = 2;</code>
       */
      public Builder setLength(int value) {
        bitField0_ |= 0x00000002;
        length_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 length = 2;</code>
       */
      public Builder clearLength() {
        bitField0_ = (bitField0_ & ~0x00000002);
        length_ = 0;
        onChanged();
        return this;
      }

      private long accessCounter_ ;
      /**
       * <code>required int64 access_counter = 3;</code>
       */
      public boolean hasAccessCounter() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required int64 access_counter = 3;</code>
       */
      public long getAccessCounter() {
        return accessCounter_;
      }
      /**
       * <code>required int64 access_counter = 3;</code>
       */
      public Builder setAccessCounter(long value) {
        bitField0_ |= 0x00000004;
        accessCounter_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 access_counter = 3;</code>
       */
      public Builder clearAccessCounter() {
        bitField0_ = (bitField0_ & ~0x00000004);
        accessCounter_ = 0L;
        onChanged();
        return this;
      }

      private int deserialiserIndex_ ;
      /**
       * <code>required int32 deserialiser_index = 4;</code>
       */
      public boolean hasDeserialiserIndex() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>required int32 deserialiser_index = 4;</code>
       */
      public int getDeserialiserIndex() {
        return deserialiserIndex_;
      }
      /**
       * <code>required int32 deserialiser_index = 4;</code>
       */
      public Builder setDeserialiserIndex(int value) {
        bitField0_ |= 0x00000008;
        deserialiserIndex_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 deserialiser_index = 4;</code>
       */
      public Builder clearDeserialiserIndex() {
        bitField0_ = (bitField0_ & ~0x00000008);
        deserialiserIndex_ = 0;
        onChanged();
        return this;
      }

      private int priority_ = 0;
      /**
       * <code>required .hbase.pb.BlockPriority priority = 5;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>required .hbase.pb.BlockPriority priority = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority getPriority() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority result = org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority.valueOf(priority_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority.single : result;
      }
      /**
       * <code>required .hbase.pb.BlockPriority priority = 5;</code>
       */
      public Builder setPriority(org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BlockPriority value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        priority_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.BlockPriority priority = 5;</code>
       */
      public Builder clearPriority() {
        bitField0_ = (bitField0_ & ~0x00000010);
        priority_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BucketEntry)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BucketEntry)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketEntry>
        PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BucketEntry>() {
      public BucketEntry parsePartialFrom(
          org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
          org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
          return new BucketEntry(input, extensionRegistry);
      }
    };

    public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketEntry> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BucketEntry> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.BucketCacheProtos.BucketEntry getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BucketCacheEntry_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BucketCacheEntry_fieldAccessorTable;
  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_fieldAccessorTable;
  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BackingMap_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BackingMap_fieldAccessorTable;
  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BackingMapEntry_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BackingMapEntry_fieldAccessorTable;
  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BlockCacheKey_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BlockCacheKey_fieldAccessorTable;
  private static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BucketEntry_descriptor;
  private static final 
    org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BucketEntry_fieldAccessorTable;

  public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\026BucketCacheEntry.proto\022\010hbase.pb\"\366\001\n\020B" +
      "ucketCacheEntry\022\026\n\016cache_capacity\030\001 \002(\003\022" +
      "\020\n\010io_class\030\002 \002(\t\022\021\n\tmap_class\030\003 \002(\t\022D\n\r" +
      "deserializers\030\004 \003(\0132-.hbase.pb.BucketCac" +
      "heEntry.DeserializersEntry\022)\n\013backing_ma" +
      "p\030\005 \002(\0132\024.hbase.pb.BackingMap\0324\n\022Deseria" +
      "lizersEntry\022\013\n\003key\030\001 \001(\005\022\r\n\005value\030\002 \001(\t:" +
      "\0028\001\"6\n\nBackingMap\022(\n\005entry\030\001 \003(\0132\031.hbase" +
      ".pb.BackingMapEntry\"]\n\017BackingMapEntry\022$" +
      "\n\003key\030\001 \002(\0132\027.hbase.pb.BlockCacheKey\022$\n\005",
      "value\030\002 \002(\0132\025.hbase.pb.BucketEntry\"Q\n\rBl" +
      "ockCacheKey\022\021\n\thfilename\030\001 \002(\t\022\016\n\006offset" +
      "\030\002 \002(\003\022\035\n\025primary_replica_block\030\003 \002(\010\"\214\001" +
      "\n\013BucketEntry\022\016\n\006offset\030\001 \002(\003\022\016\n\006length\030" +
      "\002 \002(\005\022\026\n\016access_counter\030\003 \002(\003\022\032\n\022deseria" +
      "liser_index\030\004 \002(\005\022)\n\010priority\030\005 \002(\0162\027.hb" +
      "ase.pb.BlockPriority*2\n\rBlockPriority\022\n\n" +
      "\006single\020\000\022\t\n\005multi\020\001\022\n\n\006memory\020\002BN\n1org." +
      "apache.hadoop.hbase.shaded.protobuf.gene" +
      "ratedB\021BucketCacheProtosH\001\210\001\001\240\001\001"
    };
    org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry assignDescriptors(
              org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
    internal_static_hbase_pb_BucketCacheEntry_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_BucketCacheEntry_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BucketCacheEntry_descriptor,
        new java.lang.String[] { "CacheCapacity", "IoClass", "MapClass", "Deserializers", "BackingMap", });
    internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_descriptor =
      internal_static_hbase_pb_BucketCacheEntry_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BucketCacheEntry_DeserializersEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_hbase_pb_BackingMap_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_BackingMap_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BackingMap_descriptor,
        new java.lang.String[] { "Entry", });
    internal_static_hbase_pb_BackingMapEntry_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_BackingMapEntry_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BackingMapEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_hbase_pb_BlockCacheKey_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_BlockCacheKey_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BlockCacheKey_descriptor,
        new java.lang.String[] { "Hfilename", "Offset", "PrimaryReplicaBlock", });
    internal_static_hbase_pb_BucketEntry_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_BucketEntry_fieldAccessorTable = new
      org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BucketEntry_descriptor,
        new java.lang.String[] { "Offset", "Length", "AccessCounter", "DeserialiserIndex", "Priority", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
